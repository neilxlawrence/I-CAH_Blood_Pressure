Load packages and reread files using the prebuilt load files function

```{r, load software packages}
rm(list = ls())

#we first establish the location of the working directory where we keep everything, depending on whether it exists (i.e. which computer we are using)
#check C drive
if(file.exists("C:/Users/User/Documents/NRL_R_work/iCAH_Blood_pressure")){
location_of_main_folder <-
  "C:/Users/User/Documents/NRL_R_work/iCAH_Blood_pressure"
}

#take the working directory otherwise, which should work every time
if(!exists("location_of_main_folder")){
  location_of_main_folder <- getwd()
}

#paste the name of our functions folder into the path name
location_of_functions_folder <-
  paste0(location_of_main_folder, "/bp_functions_folder/")

#load the function that loads all the libraries and sources
source(paste0(location_of_functions_folder, "load_bp_libraries_and_sources_function.R"))

#paste together the location of the data files - we don't load in the first file, but we need this location for the end
location_of_data_files <-
  paste0(location_of_main_folder, "/bp_data_files_to_load/")

#run the function, pointing it towards the functions folder
load_bp_libraries_and_sources_function(
  location_of_functions_folder=location_of_functions_folder,
  location_of_data_files=location_of_data_files
)

print("Note we we only load longitudinal data to review if a visit date is also present in the longitudinal data, we DO NOT yet join the frames:")

#we load the bp_participants just to compare dates of visits
load_bp_files_function(previous_file_name = "file_3",
  parent_directory = location_of_data_files,
  list_of_data_frames_to_load=list("bp_participants_longitudinal_data"))
```

before we load the labs data, we can pull out all the visit dates from the longitudinal data we have that we will use later to check against

```{r, establish dates within longitudinal data to create a vector through which to check}
#we also want to know if that assessment date is present for that patient in bp_participants_longitudinal_data
bp_participants_longitudinal_visit_dates <-
  bp_participants_longitudinal_data[,c(
    "id",
    "visit_date")]

#rename that to tell us what frame it is coming from
names(bp_participants_longitudinal_visit_dates)[names(
  bp_participants_longitudinal_visit_dates)=="visit_date"] <- 
  "longitudinal_visit_date"

#we don't want to join those, we want to paste them together. then we can simply list the pasted id and longitudinal visit date, and get the other frame to check if the pasted id labs visit date is in that list
longitudinal_id_visit_dates_vector_to_check <-
  as.vector(paste0(bp_participants_longitudinal_visit_dates$id,
                   "_",
                   bp_participants_longitudinal_visit_dates$longitudinal_visit_date))

#put that into a frame purely for purposes of looking inside the console
longitudinal_id_visit_dates_vector_to_check_frame <- 
  as.data.frame(longitudinal_id_visit_dates_vector_to_check)
```

```{r, load labs data and pull out original versions of columns}
bp_labs <- 
  bp_labs_original <-
  read.csv("./2021-12-01 Data extraction for ICAH BP study/STUDY ID 202107_NL BP CAH/STUDY BP CAH labs.csv", 
           header=T, 
           na.strings="NULL")

#order the original frame and reprint it back into the working directory just for easy manual review
bp_labs_original_ordered <- 
  bp_labs_original[order(bp_labs_original$record_id,
         bp_labs_original$assessment_id),] 
write.csv(bp_labs_original_ordered, "bp_labs_original_ordered.csv", row.names=F)

print("number of rows in the lab results frame")

nrow(bp_labs)
```

```{r, check assessment_date is entered in the same format throughout}
bp_labs$unexpected_assessment_date_format <-
  ifelse(grepl("\\d{2}/\\d{2}/\\d{4}", bp_labs$assessment_date),
         0,
         1)

print("This number shows the number of assessment_date that are in an unexpected format and will need adjustment below")

sum(bp_labs$unexpected_date_format)

print("If that last number isn't zero, you have to ensure that there is manual correction of columns that have been entered in a different format")

#in our case in the bp extraction, the date 2008/02/03 needs correcting to 03/02/2008
```

```{r, check labs_date_time is entered in the same format throughout}
bp_labs$expected_data_and_time_format <-
  ifelse(grepl("^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}$", bp_labs$date_and_time),
         1,
         0)

print("This number shows the number of data_and_time that are in an expected format and will need adjustment below")

sum(bp_labs$expected_data_and_time_format) 

print("Number of date_and_time that is NA")

sum(is.na(bp_labs$date_and_time))

bp_labs$unexpected_data_and_time_format <-
  ifelse(grepl("^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}$", bp_labs$date_and_time),
         0,
         1)

print("This number shows the number of data_and_time that are in an unexpected format and will need adjustment below")

sum(bp_labs$unexpected_data_and_time_format) - sum(is.na(bp_labs$date_and_time))

print("If that last number isn't zero, you have to ensure that there is manual correction of columns that have been entered in a different format")
```

```{r, create column names and missing data percentage files to refer to}
column_names_and_missing_percentages_bp_labs_original <-
  data.frame(
    Column=colnames(bp_labs_original),
    Percentage_complete=NA
  )

#create a loop to report the percentage complete
for (i in 1:length(column_names_and_missing_percentages_bp_labs_original$Column)){
  each_column <- column_names_and_missing_percentages_bp_labs_original[i,1]

  column_names_and_missing_percentages_bp_labs_original[i,"Percentage_complete"] <- 
    round(100*
      sum(!is.na(bp_labs_original[,c(each_column)])) / 
      length(bp_labs_original[,c(each_column)]), digits=1)
}

dir.create("Column_Names_and_missing_percentages")

write.csv(column_names_and_missing_percentages_bp_labs_original, 
          "./Column_Names_and_missing_percentages/colnames_and_missing_percentage_bp_labs_original.csv", 
          row.names=F)
```

```{r, create original versions of columns in order to compare at the end of the file how many have changed}
#there are different named columns here that report the same thing
bp_labs$original_assessment_date <-
  bp_labs$assessment_date

bp_labs$original_date_and_time <-
  bp_labs$date_and_time

bp_labs$assessment_date_original <-
  bp_labs$assessment_date

bp_labs$date_and_time_original <-
  bp_labs$date_and_time

bp_labs$labs_type_original <-
  bp_labs$labs_type

bp_labs$value_original <-
  bp_labs$value
```

```{r, prove assessment date and assessment_id are always on the same date}
#paste assessment date and assessment id together
bp_labs$assessment_date_check <- 
  paste0(bp_labs$assessment_id, 
         "_",
         bp_labs$assessment_date)

print("number of different assessment id's should be same as number of different assessment dates, therefore this number should be zero:")

#count the number of the pasted assessment date and id and compare to number of assessment id's alone
length(unique(bp_labs$assessment_date_check)) - length(unique(bp_labs$assessment_id))

#then we can remove that column
bp_labs$assessment_date_check <- NULL
```

```{r, remove exact duplicate entries from labs data}
#straight away we can get rid of rows in this frame that are completely identical
unique_bp_labs <- 
  unique(bp_labs)

print("number of rows in original file")

nrow(unique_bp_labs)

print("number of rows removed that are completely identical to another one in the bp labs extraction:")

number_of_exact_row_duplicates_removed <- 
  nrow(bp_labs) - nrow(unique_bp_labs)

number_of_exact_row_duplicates_removed
```

```{r, remove duplicate entries from labs data with different assessment_id}
print("we notice that if labs are entered twice in a different record, but the date_and_time recorded of the lab sample itself is exactly the same, then this is an inadvertent duplicate. We don't need to get rid of NAs for this, we just need to paste all columns together. We don't want 'result' because this is just high low etc and may have been a correction, this duplication needs flagging and reducing to just one entry.")

#for duplicate combinations we can just crudely paste together columns of interest
unique_bp_labs$unique_combination_paste <-
  paste0(unique_bp_labs$record_id, 
         unique_bp_labs$assessment_date, 
         unique_bp_labs$labs_type, 
         unique_bp_labs$date_and_time, 
         unique_bp_labs$value, 
         unique_bp_labs$centreName)

#then we assess the frequencies
duplication_check <- 
  subset(rownames_to_column(
    as.data.frame(freq(
      unique_bp_labs$unique_combination_paste))),
         rowname!="<NA>" & 
      rowname!="Total" & Freq > 1)

#take those rows out to review
bp_labs_duplications_to_rationalise <- 
  subset(unique_bp_labs, unique_combination_paste %in% duplication_check$rowname)

#within the original frame then remove all duplications
bp_labs_duplications_removed <-
  subset(unique_bp_labs, !(unique_combination_paste %in% duplication_check$rowname))

print("The following number should be zero:")  

nrow(bp_labs_duplications_removed) + 
  nrow(bp_labs_duplications_to_rationalise) - 
  nrow(unique_bp_labs)

#within the duplication frame we can slice_max using the assessment_id
bp_labs_duplications_to_bind_back <-
  bp_labs_duplications_to_rationalise %>%
  group_by(unique_combination_paste) %>%
  slice_max(order_by=assessment_id,
            n=1,
            with_ties = F
            )

#now we can bind them back
bp_labs_without_duplications <-
  rbind(bp_labs_duplications_removed,
        bp_labs_duplications_to_bind_back)

print("removing duplications with different assessment ids has resulted in the removal of the following number of rows:")

number_duplicated_with_different_assessment_id <- 
  nrow(unique_bp_labs) - nrow(bp_labs_without_duplications)

number_duplicated_with_different_assessment_id

print("Original number of rows in frame")

nrow(bp_labs_original)

print("Total number of duplicated rows removed is:")

number_of_exact_row_duplicates_removed + number_duplicated_with_different_assessment_id

print("Note, I originally used to remove duplications later on, but it is now done to help with outlier detection and data entry from the outset")

print("Number of patients that had duplicated entries:")

length(unique(bp_labs_duplications_to_rationalise$record_id))

#now we can rationalise the frame name
bp_labs <- 
  bp_labs_without_duplications

print("we also assess duplications with a different visit_date, but first we do some manual corrections that are flagged by that following process, just coded first:")
```

##########################################################################
Coding to allow manual identification and plotting of likely incorrect dates in lab data
##########################################################################

```{r, lag columns to diagnose differences between date_and_time within assessment_id and differences in chronology}
#now we have one reading per assessment id, we can order by id, ready to lag the frame
bp_labs <- 
  bp_labs[order(bp_labs$record_id,
                           bp_labs$assessment_id),] 

#lag the record_id
bp_labs$lag_record_id <- 
  lag(bp_labs$record_id)

#lag the assessment_id
bp_labs$lag_assessment_id <- 
  lag(bp_labs$assessment_id)

#make a posix visit date
bp_labs$labs_visit_date <- 
  as.POSIXct(bp_labs$assessment_date, format="%d/%m/%Y")

#we also want an id and labs_visit_date paste to check against a list of longitudinal visit dates pasted to the ids
bp_labs$id_labs_visit_date_check <- 
  paste0(bp_labs$record_id, 
         "_",
         bp_labs$labs_visit_date)

#lag the visit date
bp_labs$lag_labs_visit_date <- 
  lag(bp_labs$labs_visit_date)

#flag if the previous visit date is afterwards in time than the current visit date
bp_labs$same_patient_back_in_time <-
  ifelse(bp_labs$record_id==bp_labs$lag_record_id &
           difftime(bp_labs$lag_labs_visit_date, 
                    bp_labs$labs_visit_date, units="days") > 0,
         1,
         0)

#lag the date_and_time
bp_labs$lag_date_and_time <- 
  lag(bp_labs$date_and_time)

#flag different date_and_time within assessment_id
bp_labs$different_date_and_time_within_same_assessment_id <-
  ifelse(bp_labs$assessment_id==bp_labs$lag_assessment_id &
         bp_labs$date_and_time!= bp_labs$lag_date_and_time,
         1,
         0)

all_bp_labs_with_different_date_and_time_within_same_assessment_id <-
  subset(bp_labs , different_date_and_time_within_same_assessment_id==1)

all_bp_labs_without_different_date_and_time_within_same_assessment_id <-
  subset(bp_labs , different_date_and_time_within_same_assessment_id==0)

all_bp_labs_without_date_and_time <-
  subset(bp_labs , is.na(date_and_time))

print("the following number should be zero to show we aren't losing any rows from separating into those patients with and without different date and time within the same assessment id")

length(nrow(all_bp_labs_with_different_date_and_time_within_same_assessment_id) +
         nrow(all_bp_labs_without_different_date_and_time_within_same_assessment_id) +
         nrow(all_bp_labs_without_date_and_time$date_and_time) -
         nrow(bp_labs))
```

```{r, calculate differences between labs visit date and labs marker date}
#we compare bp_labs$labs_visit_date which we have already made above to the visit_date that we must extract first from the date and time column:

bp_labs$labs_date_from_date_and_time_of_measurement <-
  as.POSIXct(
    gsub(x=bp_labs$date_and_time,
       pattern="T.*",
       replacement=""), format="%Y-%m-%d")

#paste together the id and the date that we take from the actual blood readings. We can then use this to detect if that date is seen in a longitudinal visit. This will help us see if the labs visit date is likely to be wrong, or if is the labs date and time of measurement that is wrong

bp_labs$id_labs_date_from_date_and_time_of_measurement_check <- 
  paste0(bp_labs$record_id, 
         "_",
         bp_labs$labs_date_from_date_and_time_of_measurement)

#we can  detect if the labs date from the measurement of marker is present in the longitudinal data
bp_labs$labs_date_and_time_present_in_longitudinal_data <-
  ifelse(bp_labs$id_labs_date_from_date_and_time_of_measurement_check %in% 
           longitudinal_id_visit_dates_vector_to_check,
         1,
         0)

#take the difference between the labs visit date, and the date from the measurement of marker in the labs frame
bp_labs$labs_visit_date_labs_reading_date_difference_in_days <-
  as.numeric(difftime(bp_labs$labs_visit_date, 
           bp_labs$labs_date_from_date_and_time_of_measurement,
           units="days"))

#give that a flag if we have a difference between the labs visit date and the labs taken from the marker reading
bp_labs$internal_date_difference <- 
  ifelse(bp_labs$labs_visit_date_labs_reading_date_difference_in_days!=0,
         1,
         0)

#we use the vector of id_visit_dates from the longitudinal visits to tell us whether that id and visit date from the labs visits is present
bp_labs$labs_assessment_date_present_in_longitudinal_data <-
  ifelse(bp_labs$id_labs_visit_date_check %in% 
           longitudinal_id_visit_dates_vector_to_check,
         1,
         0)

#give us another flag for there being an internal_date_difference and the labs_visit_date not being in longitudinal data
bp_labs$internal_date_difference_AND_visit_NOT_present_in_longitudinal_data <-
  ifelse(bp_labs$labs_assessment_date_present_in_longitudinal_data==0 &
         bp_labs$labs_visit_date_labs_reading_date_difference_in_days==1,
         1,
         0)

```

```{r, share date_and_time of lab measurements with other measurements within the same visit if the date_and_time is missing}
#take out all the rows from assessments that contain one assessment that doesn't have a date_and_time. If there are some date_and_time values in this, then they may be able to be shared with the missing data
bp_labs_with_shareable_date_and_time <-
  subset(bp_labs, assessment_id %in% all_bp_labs_without_date_and_time$assessment_id)

#because that frame does have some date_and_time in it, we know that some of the NA date_and_time could potentially be shareable. This is certainly an assumption, but one that is better than just using the visit_date which Jillian mentioned - it's more likely all the bloods were done on the same day
#take out just the assessment_id and date_and_time because that's all we want to join back in, and make it unique
bp_labs_with_shareable_date_and_time <-
  unique(bp_labs_with_shareable_date_and_time[,c(
    "assessment_id",
    "date_and_time")])

#subset just the dates_and_times present to share and join back in by getting rid of na's
bp_labs_with_shareable_date_and_time_to_join <-
  subset(
    bp_labs_with_shareable_date_and_time, !is.na(date_and_time)
  )

#rename the column we want to join back in 
names(bp_labs_with_shareable_date_and_time_to_join)[names(
  bp_labs_with_shareable_date_and_time_to_join)=="date_and_time"] <- 
  "shareable_date_and_time_from_same_assessment_id"
print("number of shareable dates and times that we can use amongst readings within the same assessment_id:")
nrow(bp_labs_with_shareable_date_and_time_to_join)

#we find that some of the shareable dates actually have multiple dates, and therefore can't be easily joined. We need to filter these out
assessment_ids_with_too_many_shareable_dates <-
  as.vector(
    subset(
      rownames_to_column(
        as.data.frame(
          freq(
            bp_labs_with_shareable_date_and_time_to_join$assessment_id))), 
      rowname!="Total" & 
        rowname!="<NA>" & 
        Freq>1)$rowname)

#we can then use that vector of assessment_ids to alter that shareable date_and_time
bp_labs_with_shareable_date_and_time_to_join$shareable_date_and_time_from_same_assessment_id <-
  ifelse(bp_labs_with_shareable_date_and_time_to_join$assessment_id %in%
           assessment_ids_with_too_many_shareable_dates,
         "more_than_one_possible_shareable_date_and_time",
         bp_labs_with_shareable_date_and_time_to_join$shareable_date_and_time_from_same_assessment_id)

#now this can be made unique so that we don't have a many to one relationship when we join
bp_labs_with_shareable_date_and_time_to_join <-
  unique(bp_labs_with_shareable_date_and_time_to_join)

#now join our shareable dates
bp_labs_with_shareable_date_and_times_joined <-
  left_join(bp_labs, 
            bp_labs_with_shareable_date_and_time_to_join,
            by = join_by(assessment_id))

print("we started with this many rows:")
nrow(bp_labs)

print("joined this many rows:")
nrow(bp_labs_with_shareable_date_and_time_to_join)

print("and are left with this many rows:")
nrow(bp_labs_with_shareable_date_and_times_joined)

print("so this number should be zero:")
nrow(bp_labs_with_shareable_date_and_times_joined) -
  nrow(bp_labs)

#we can then rationalise the file name
bp_labs <- 
  bp_labs_with_shareable_date_and_times_joined

#now we have our shareable dates and times in the correct frame, we can replace NA's with the shareable dates and times
bp_labs$date_and_time <-
  ifelse(is.na(bp_labs$date_and_time) &
           !is.na(bp_labs$shareable_date_and_time_from_same_assessment_id) &
           bp_labs$shareable_date_and_time_from_same_assessment_id!="more_than_one_possible_shareable_date_and_time",
         bp_labs$shareable_date_and_time_from_same_assessment_id,
         bp_labs$date_and_time)

print("we have now shared all the possible date_and_time values within the same assessment_id that we can. If patients had multiple possible date_and_time's within the same assessment_id, then the missing ones remain NA.")
```

```{r, establish patients with different date_and_time within the same assessment_id}
patients_with_different_date_and_time_within_same_assessment_id <-
  unique(all_bp_labs_with_different_date_and_time_within_same_assessment_id$record_id)

patients_without_different_date_and_time_within_same_assessment_id <-
  unique(all_bp_labs_without_different_date_and_time_within_same_assessment_id$record_id)

print("number of patients_with_different_date_and_time_within_same_assessment_id")

length(patients_with_different_date_and_time_within_same_assessment_id)

#establish which assessment_dates have a variable date_and_time for the same visit_date

bp_labs$back_in_time_AND_visit_NOT_present_in_longitudinal_data <-
  ifelse(bp_labs$labs_assessment_date_present_in_longitudinal_data==0 &
         bp_labs$same_patient_back_in_time==1,
         1,
         0)

print("the number who have an entry from a previous time later on is:")
sum(bp_labs$same_patient_back_in_time, na.rm=T)

print("the number who have an entry for a date that isn't present in the longitudinal data is:")
sum(bp_labs$labs_assessment_date_present_in_longitudinal_data==0)

print("the number who have an entry for a date that isn't present in the longitudinal data AND is a back in time entry is:")
sum(bp_labs$back_in_time_AND_visit_NOT_present_in_longitudinal_data, na.rm=T)
```

```{r, assessing entries that have been allied to a different visit date}
#for duplicate combinations we can just crudely paste together columns of interest
bp_labs$unique_combination_paste_2 <-
  paste0(bp_labs$record_id, 
         bp_labs$labs_type, 
         bp_labs$date_and_time, 
         bp_labs$value, 
         bp_labs$centreName)

#then we assess the frequencies
duplication_check_2 <- 
  subset(rownames_to_column(
    as.data.frame(freq(
      bp_labs$unique_combination_paste_2))),
         rowname!="<NA>" & 
         rowname!="Total" & 
         Freq > 1)

#take those rows out to review
bp_labs_duplications_to_review_2 <- 
  subset(bp_labs, unique_combination_paste_2 %in% duplication_check_2$rowname)

#this time, if we have a missing date_and_time we are on a hiding to nothing, because this likely is simply from a different visit and the date_and_time are missing, rather than them being an inadvertent duplication. So get rid of NA's
bp_labs_duplications_to_review_2 <-
  subset(bp_labs_duplications_to_review_2, 
         !is.na(date_and_time))

#first we establish a vector of those unique_combination_paste_2 that has either of the entries in the longitudinal frame by subsetting
bp_labs_duplications_to_review_2_in_longitudinal_data <-
  subset(bp_labs_duplications_to_review_2, labs_assessment_date_present_in_longitudinal_data==1)

#we can take out a vector of the unique_combination_paste_2 that has a reading present in longitudinal data
unique_combination_paste_2_has_a_labs_assessment_date_present_in_longitudinal_data <-
  bp_labs_duplications_to_review_2_in_longitudinal_data$unique_combination_paste_2

#now we turn that into a column in the frame for us to be able to refer to within an ifelse statement
bp_labs_duplications_to_review_2$unique_combination_paste_2_has_a_labs_assessment_date_present_in_longitudinal_data <-
  ifelse(bp_labs_duplications_to_review_2$unique_combination_paste_2 %in% 
           unique_combination_paste_2_has_a_labs_assessment_date_present_in_longitudinal_data,
         1,
         0)

#we can get rid of the readings where the unique_combination_paste_2_has_a_labs_assessment_date_present_in_longitudinal_data, but the labs_assessment_date_present_in_longitudinal_data is 0, as this is a safe assumption that the one not present in the longitudinal data is a mistaken entry, and simply a duplication of the lab test entry
bp_labs_duplications_to_review_2$duplication_of_same_blood_test_allied_to_wrong_visit_date_to_remove <-
  ifelse(bp_labs_duplications_to_review_2$unique_combination_paste_2_has_a_labs_assessment_date_present_in_longitudinal_data==1 &
           bp_labs_duplications_to_review_2$labs_assessment_date_present_in_longitudinal_data==0,
         1,
         0)

#we can flag those that have a difference of zero. If lab readings have a difference of zero compared to any other difference with the visit date, then the result is much much more likely to be from the same day as the visit date, provided the visit date is in the longitudinal data 
bp_labs_duplications_to_review_2_in_longitudinal_data_and_zero_difference_between_dates <-
  subset(bp_labs_duplications_to_review_2_in_longitudinal_data, 
         labs_visit_date_labs_reading_date_difference_in_days==0)

nrow(bp_labs_duplications_to_review_2_in_longitudinal_data_and_zero_difference_between_dates)

unique_combination_paste_2_has_a_labs_assessment_date_present_in_longitudinal_data_and_zero_difference_between_dates <-
  bp_labs_duplications_to_review_2_in_longitudinal_data_and_zero_difference_between_dates$unique_combination_paste_2

#now we turn that into a column in the frame for us to be able to refer to within an ifelse statement
bp_labs_duplications_to_review_2$unique_combination_paste_2_has_a_labs_assessment_date_present_in_longitudinal_data_and_zero_difference_between_dates <-
  ifelse(bp_labs_duplications_to_review_2$unique_combination_paste_2 %in% 
           unique_combination_paste_2_has_a_labs_assessment_date_present_in_longitudinal_data_and_zero_difference_between_dates,
         1,
         0)

#now we can flag them to remove, if they don't have zero difference between dates but their duplicate does
bp_labs_duplications_to_review_2$flag_for_removal <-
  ifelse(bp_labs_duplications_to_review_2$unique_combination_paste_2_has_a_labs_assessment_date_present_in_longitudinal_data_and_zero_difference_between_dates==1 &
           bp_labs_duplications_to_review_2$labs_visit_date_labs_reading_date_difference_in_days!=0,
         1,
         0)

#we remove them from this frame, that will be manually reviewed
bp_labs_duplications_to_review_2 <-
  subset(bp_labs_duplications_to_review_2, flag_for_removal==0)

#we also need to remove them from the main frame 
bp_labs_duplications_to_remove <-
  subset(bp_labs_duplications_to_review_2, flag_for_removal==1)

print("bp_labs number of rows before duplications removed:")
nrow(bp_labs)

#then we take those out of the main frame:
bp_labs <-
  subset(bp_labs, !(unique_combination_paste_2 %in% bp_labs_duplications_to_remove$unique_combination_paste_2))

print("bp_labs number of rows after duplications removed:")
nrow(bp_labs)

print("it's possible those two numbers are the same if there aren't any duplications")

#after that we have to perform manual review, because its just too difficult to say which is the correct visit date to ally these tests to 
#to perform manual review, we need all the readings for the patients within the frame bp_labs_duplications_to_review_2
patients_with_duplicated_bloods_allied_to_different_visits <-
  unique(bp_labs_duplications_to_review_2$record_id)

bp_labs_full_frame_duplications_to_review_2 <-
  subset(bp_labs, 
         record_id %in% patients_with_duplicated_bloods_allied_to_different_visits)

#wihthin that frame flag the rows to review
bp_labs_full_frame_duplications_to_review_2$review_duplicate_lab_different_visit <-
  ifelse(bp_labs_full_frame_duplications_to_review_2$assessment_id %in%
           bp_labs_duplications_to_review_2$assessment_id,
         1,
         0)

write.csv(bp_labs_full_frame_duplications_to_review_2, 
          "bp_labs_full_frame_duplications_to_review_2.csv", 
          row.names = F)

print("Review the frame bp_labs_full_frame_duplications_to_review_2.csv to establish which duplicated bloods should be allied to which visit. If within the flagged rows some have a labs_visit_date_labs_reading_date_difference_in_days that is 0 in some and a value in others it is likely to be the 0 readings that are valid")
```

```{r, take out all of the readings for patients who have been flagged for manual review as back in time AND not in longitudinal data}
#filtering to check any back in time:

#first we check which patients have chronological reversed rows by taking out those rows from the frame
bp_labs_chronological_reversed_rows <-
  bp_labs %>%
  filter(back_in_time_AND_visit_NOT_present_in_longitudinal_data==1) 

#then take the patients out of that frame so we know which patients have any chronologically reversed rows
patients_with_chronological_reversed_rows <-
  bp_labs_chronological_reversed_rows$record_id

#and correct that total frame to include all the visits from the flagged patients
bp_labs_from_patients_with_chronological_reversed_rows <-
  subset(bp_labs, record_id %in% patients_with_chronological_reversed_rows)

#then we want rows with different date_and_time within the same assessment_id
bp_labs_rows_with_different_date_and_time_within_same_assessment_id <-
  bp_labs %>%
  filter(different_date_and_time_within_same_assessment_id==1) 

#then we take patients with rows with different date_and_time within the same assessment_id
patients_with_rows_with_different_date_and_time_within_same_assessment_id <-
  unique(bp_labs_rows_with_different_date_and_time_within_same_assessment_id$record_id)

#now we need to correct that frame so we get all the rows for those patients
bp_labs_rows_from_patients_with_different_date_and_time_within_same_assessment_id <-
  bp_labs %>%
  filter(record_id %in% patients_with_rows_with_different_date_and_time_within_same_assessment_id)

#then we want other patients - patients that only have rows with the same date_and_time within the same_assessment_id. This is the compliment of those with different ones, so first get a list of all patients
all_patient_ids_in_labs_frame <-
  unique(bp_labs$record_id)

#use not in to take the patents with the same date_and-time within same_assessment_id
bp_labs_rows_from_patients_with_same_date_and_time_within_same_assessment_id <-
  bp_labs %>%
  filter(!(record_id %in% patients_with_rows_with_different_date_and_time_within_same_assessment_id))

#then we take patients with same date_and_time_within the same assessment_id
patients_with_rows_with_same_date_and_time_within_same_assessment_id <-
  unique(bp_labs_rows_from_patients_with_same_date_and_time_within_same_assessment_id$record_id)

print("this number should be zero, to prove that we have the full number of patients accounted for:")
length(all_patient_ids_in_labs_frame)-
  length(patients_with_rows_with_different_date_and_time_within_same_assessment_id)-
  length(patients_with_rows_with_same_date_and_time_within_same_assessment_id)

print("this number should be zero, to prove that we have the full number of rows accounted for:")
nrow(bp_labs)-
  nrow(bp_labs_rows_from_patients_with_different_date_and_time_within_same_assessment_id)-
  nrow(bp_labs_rows_from_patients_with_same_date_and_time_within_same_assessment_id)

#we can now separately assess those that have a chronological data entry flag in those with a the same date_and_time within assessment id, which can be done in a frame with just one row per assessment_id

bp_labs_chronological_reversed_rows_with_same_date_and_time_throughout_assessment_to_review <-
  subset(bp_labs_from_patients_with_chronological_reversed_rows,
         record_id %in% patients_with_rows_with_same_date_and_time_within_same_assessment_id)

#because we know the date_and_time is the same throughout the assessment_id in these patients, we can take out just the top row of assessment_id 

bp_labs_chronological_reversed_rows_with_same_date_and_time_throughout_assessment_to_review <- 
  bp_labs_chronological_reversed_rows_with_same_date_and_time_throughout_assessment_to_review %>%
  group_by(assessment_id) %>%
  slice_max(assessment_id,
           n=1,
            with_ties = F)

#order before printing to csv

bp_labs_chronological_reversed_rows_with_same_date_and_time_throughout_assessment_to_review <- 
  bp_labs_chronological_reversed_rows_with_same_date_and_time_throughout_assessment_to_review[
    order(
      bp_labs_chronological_reversed_rows_with_same_date_and_time_throughout_assessment_to_review$record_id,
      bp_labs_chronological_reversed_rows_with_same_date_and_time_throughout_assessment_to_review$assessment_id),] 

#print that to csv for manual review
write.csv(
  bp_labs_chronological_reversed_rows_with_same_date_and_time_throughout_assessment_to_review,
  "bp_labs_chronological_reversed_rows_with_same_date_and_time_throughout_assessment_to_review.csv", 
  row.names = F)

#we now secondly take those that have a chronological data entry flag in those with a DIFFERENT date_and_time within assessment id, which needs to be done in a frame with all of the markers visible

bp_labs_chronological_reversed_rows_with_different_date_and_time_throughout_assessment_to_review <-
  subset(bp_labs_from_patients_with_chronological_reversed_rows,
         record_id %in% patients_with_rows_with_different_date_and_time_within_same_assessment_id)

#we don't slice this one, we need all the rows, just print it

#order before printing
bp_labs_chronological_reversed_rows_with_different_date_and_time_throughout_assessment_to_review <- 
  bp_labs_chronological_reversed_rows_with_different_date_and_time_throughout_assessment_to_review[
    order(
      bp_labs_chronological_reversed_rows_with_different_date_and_time_throughout_assessment_to_review$record_id,
      bp_labs_chronological_reversed_rows_with_different_date_and_time_throughout_assessment_to_review$assessment_id),] 

#print that to csv for manual review
write.csv(bp_labs_chronological_reversed_rows_with_different_date_and_time_throughout_assessment_to_review,
          "bp_labs_chronological_reversed_rows_with_different_date_and_time_throughout_assessment_to_review.csv", 
          row.names = F)

print("review the bp_labs_chronological_reversed_rows_with_different_date_and_time_throughout_assessment_to_review.csv to see if any obvious date errors have occured that can be spotted by looking for chronological data entry, appreciating that not everyone will perform chronological data entry. This frame will need to invoke changes that are separate for each marker, because there are different date_times within the same assessment_id. The visit entered back in time will be flagged, and if a visit is not entered in longitudinal data it will be flagged also. Then similarly review bp_labs_chronological_reversed_rows_with_the_same_date_and_time_throughout_assessment_to_review.csv This second file will have just one row per assessment_id present, therefore you can just change any mistakes without specifying marker")

print("when looking at the larger frame of back in time, you'll see assessment_ids that are a long way off the previous assessment id. This implies retrospective data entry, or at least a different 'session' of data entry, and therefore unlikely to be able to conclude that back in time means a mistake. Ideally you are looking for back in time (1) AND also a visit that is not in longitudinal data, so we put that into a separate column also above for easy review, and now filter by that stronger signal that it is a data entry mistake. ")
```

######################################################################################################
plotting different assessment_date and date_and_time for visual review
######################################################################################################

```{r, plot of visit dates and lab dates to diagnose incorrectly allied visits}
#note here you can change this to original_assessment_date and original_date_and_time to get what happened before the changes
original_data_to_plot <-
  rownames_to_column(
    bp_labs[,c(
      "record_id",
      "assessment_id",
      "original_assessment_date",
      "original_date_and_time")])

#note here you can change this to original_assessment_date and original_date_and_time to get what happened before the changes
adjusted_data_to_plot <-
  rownames_to_column(
    bp_labs[,c(
      "record_id",
      "assessment_id",
      "assessment_date",
      "labs_date_from_date_and_time_of_measurement")])

#make the data types approrpiate
adjusted_data_to_plot$rowname <- 
  as.numeric(adjusted_data_to_plot$rowname)

original_data_to_plot$rowname <- 
  as.numeric(original_data_to_plot$rowname)

#make dates appropriate posix objects
adjusted_data_to_plot$assessment_date <- 
  as.POSIXct(adjusted_data_to_plot$assessment_date, 
             format="%d/%m/%Y")

adjusted_data_to_plot$labs_date_from_date_and_time_of_measurement <- 
  as.POSIXct(adjusted_data_to_plot$labs_date_from_date_and_time_of_measurement, 
             format="%Y-%m-%d")

original_data_to_plot$assessment_date <- 
  as.POSIXct(original_data_to_plot$original_assessment_date, 
             format="%d/%m/%Y")

original_data_to_plot$labs_date_from_date_and_time_of_measurement <- 
  as.POSIXct(original_data_to_plot$original_date_and_time, 
             format="%Y-%m-%d")

#make the data longer to facilitate a gg plot where we can join the dates with lines
adjusted_data_to_plot_long <- 
  pivot_longer(
    data=adjusted_data_to_plot,
    cols=c("assessment_date", 
           "labs_date_from_date_and_time_of_measurement"),
    names_to="date_type",
    values_to="date_value"
  )

original_data_to_plot_long <- 
  pivot_longer(
    data=original_data_to_plot,
    cols=c("assessment_date", 
           "labs_date_from_date_and_time_of_measurement"),
    names_to="date_type",
    values_to="date_value"
  )

#make the names more palatable for the axis
adjusted_data_to_plot_long$date_type <-
  ifelse(adjusted_data_to_plot_long$date_type=="labs_date_from_date_and_time_of_measurement",
         "labs_date",
         adjusted_data_to_plot_long$date_type)

adjusted_data_to_plot_long$date_type <-
  ifelse(adjusted_data_to_plot_long$date_type=="assessment_date",
         "visit_date",
         adjusted_data_to_plot_long$date_type)

original_data_to_plot_long$date_type <-
  ifelse(original_data_to_plot_long$date_type=="labs_date_from_date_and_time_of_measurement",
         "labs_date",
         original_data_to_plot_long$date_type)

original_data_to_plot_long$date_type <-
  ifelse(original_data_to_plot_long$date_type=="assessment_date",
         "visit_date",
         original_data_to_plot_long$date_type)

#make a ggplot
for(id_to_plot in unique(bp_labs$record_id)){
#can test with 1951 where one date was 2000 out
#id_to_plot <- 1951    
  
adjusted_data_to_plot <-
  subset(adjusted_data_to_plot_long, record_id==id_to_plot)

original_data_to_plot <-
  subset(original_data_to_plot_long, record_id==id_to_plot)

#render a plot with adjusted data
adjusted_plot <- 
  ggplot(data=adjusted_data_to_plot,
       aes(x=date_value, y=date_type)) +
  geom_vline(
    data=subset(bp_participants_longitudinal_visit_dates, id==id_to_plot),
    aes(xintercept=longitudinal_visit_date), colour="green", alpha=0.5) +
  geom_vline(
    data=subset(adjusted_data_to_plot, date_type=="visit_date"),
    aes(xintercept=date_value), colour="red", alpha=0.5) +
  geom_vline(
    data=subset(adjusted_data_to_plot, date_type=="labs_date"),
    aes(xintercept=date_value), colour="blue", alpha=0.5) +
  geom_line(aes(group=rowname)) +
  geom_text(aes(label=assessment_id, y=2.3), angle=90, vjust=0) +
  geom_point() +
  labs(title=paste0("Adjusted data: Patient ID = ", id_to_plot),
       subtitle="assessment ID is annotated for manual review") +
  themepowerpointtitle
adjusted_plot

#render the same plot with original data
original_plot <- 
  ggplot(data=original_data_to_plot,
       aes(x=date_value, y=date_type)) +
  geom_vline(
    data=subset(bp_participants_longitudinal_visit_dates, id==id_to_plot),
    aes(xintercept=longitudinal_visit_date), colour="green", alpha=0.5) +
  geom_vline(
    data=subset(original_data_to_plot, date_type=="visit_date"),
    aes(xintercept=date_value), colour="red", alpha=0.5) +
  geom_vline(
    data=subset(original_data_to_plot, date_type=="labs_date"),
    aes(xintercept=date_value), colour="blue", alpha=0.5) +
  geom_line(aes(group=rowname)) +
  geom_text(aes(label=assessment_id, y=2.3), angle=90, vjust=0) +
  geom_point() +
  labs(title=paste0("Original data: Patient ID = ", id_to_plot),
       subtitle="assessment ID is annotated for manual review") +
  themepowerpointtitle
original_plot

#plot just the adjusted plot into a folder
dir.create("lab_date_plots")
print("saving plot for id: ")
print(id_to_plot)
ggsave(filename=paste0("Patient_ID_", id_to_plot,".tif"), 
       path="./lab_date_plots/", 
       plot = adjusted_plot, 
       device="tiff",  
       width=10, 
       height=5, 
       compression = "lzw", 
       limitsize=F)

#plot just the adjusted plot into a folder
dir.create("lab_date_plots/original_alone")

ggsave(filename=paste0("Patient_ID_", id_to_plot,".tif"), 
       path="./lab_date_plots/original_alone", 
       plot = original_plot, 
       device="tiff",  
       width=10, 
       height=5, 
       compression = "lzw", 
       limitsize=F)

#plot both adjusted and original in another separate folder
dir.create("lab_date_plots/original_comparison")

#make a grid_plot
grid_plot <-
  grid.arrange(adjusted_plot, 
               original_plot, 
               ncol=1)

ggsave(filename=paste0("Patient_ID_", id_to_plot,".tif"), 
       path="./lab_date_plots/original_comparison/", 
       plot = grid_plot, 
       device="tiff",  
       width=10, 
       height=5, 
       compression = "lzw", 
       limitsize=F)


}

sink("lab_date_plots/a_instructions_to_review_lab_date_plots.txt")

print("These plots are all individual patients. Look at the plots for black lines that span across from one visit to another. If going up and right this is a lab reading that is allied to a future visit. If there is a point above the origin of such a line, then the lab is allied to the wrong visit. If the line spans another visit, i.e. crosses another visit along its path to the one it's allied to, then it's allied to the wrong visit. Look at the bp_labs_original.csv file and check the assessment ID that you can see annotated on the plot, diagnose the nature of the problem and insert code to manually correct the dates allied to that assessment ID. The colour of the lines - 
      all lab measurement dates without a visit date are blue. 
      Longitudinal visit dates without a lab visit or lab measurement are in green. 
      Longitudinal visits without a lab measurement but with a lab visit date are in brown. 
      Longitudinal visit dates with a lab visit date and a lab measurement date are in purple. 
      
      Black lines going to a red line visit date won't be incorrectly allied, unless they cross another visit in doing so. 
      If there is a zig zag pattern of visits next to each other then there is a likely attribution error also so review those assessment_dates ")

sink()
```

**************************
reviewing visit dates that are different to lab measurement dates
**************************

following the corrections made from chronological orders of entry, we can just look at entries that have a different date to the date associated with the specific lab measurement. If this is slightly out by days or weeks this is reasonable, because bloods might be done near to an assessment, but if it's out by months or years we can spot the difference by then comparing to the longitudinal visit date frame

```{r, assess patients with a difference between visit_date and lab_date}

#take out rows with an internal date difference AND its not present in the longitudinal data
bp_labs_internal_date_difference_and_not_present_in_longitudinal_frame <- 
  subset(bp_labs, internal_date_difference_AND_visit_NOT_present_in_longitudinal_data==1)

#take out all the rows from patients that have any rows with an internal date different AND not present in longitudinal data
bp_labs_internal_date_difference_review_frame <- 
  subset(bp_labs, 
         record_id %in% bp_labs_internal_date_difference_and_not_present_in_longitudinal_frame$record_id)

descr(
  as.numeric(
    bp_labs_internal_date_difference_review_frame$labs_visit_date_labs_reading_date_difference_in_days))

freq(
  bp_labs$internal_date_difference_AND_visit_NOT_present_in_longitudinal_data)

print("reviewing patients who have an internal difference in the labs visit date and the date of lab samples themselves only flagged 3 in the BP dataset, and none of them were spurious. Instead we should approach internal visit date differences that are large. We tried this with just 1 and 2 months, but it simply flags a lot of results that look likely to be genuine - bloods just entered and allied to a visit a few months away. This will need to be considered in analysis, but can't really flag data entry error. Instead we select those that are 5 months or more away from the visit. Review bp_labs_internal_date_difference_review_frame.csv manually to spot these")

#take out patients with an internal date difference greater than a certain number of days
#here is where to enter the number of days difference between readings#
bp_labs_internal_date_difference_frame <- 
  subset(
    bp_labs, 
      labs_visit_date_labs_reading_date_difference_in_days>150 |
      labs_visit_date_labs_reading_date_difference_in_days< (-150))

#take out all patients that have an internal difference of over our threshold days specified above
patients_with_internal_date_difference_over_threshold_days <- 
  bp_labs_internal_date_difference_frame$record_id

#use those patients to take out all of the rows from the bp_labs
bp_labs_rows_from_patients_with_large_internal_date_difference <-
  subset(bp_labs, record_id %in% patients_with_internal_date_difference_over_threshold_days)

#then we want to use the frames created above to take out those with consistent time_and_date within assessment_id for review
bp_labs_internal_time_difference_rows_from_patients_with_same_date_and_time_throughout_assessment_to_review <-
  subset(bp_labs_rows_from_patients_with_large_internal_date_difference,
         record_id %in% patients_with_rows_with_same_date_and_time_within_same_assessment_id)

#because we know the date_and_time is the same throughout the assessment_id in these patients, we can take out just the top row of assessment_id 
bp_labs_internal_time_difference_rows_from_patients_with_same_date_and_time_throughout_assessment_to_review <- 
  bp_labs_internal_time_difference_rows_from_patients_with_same_date_and_time_throughout_assessment_to_review %>%
  group_by(assessment_id) %>%
  slice_max(assessment_id,
           n=1,
            with_ties = F)

#order before printing
bp_labs_internal_time_difference_rows_from_patients_with_same_date_and_time_throughout_assessment_to_review <- 
  bp_labs_internal_time_difference_rows_from_patients_with_same_date_and_time_throughout_assessment_to_review[order(bp_labs_internal_time_difference_rows_from_patients_with_same_date_and_time_throughout_assessment_to_review$record_id,
                           bp_labs_internal_time_difference_rows_from_patients_with_same_date_and_time_throughout_assessment_to_review$assessment_id),] 

write.csv(bp_labs_internal_time_difference_rows_from_patients_with_same_date_and_time_throughout_assessment_to_review,
          "bp_labs_internal_time_difference_rows_from_patients_with_same_date_and_time_throughout_assessment_to_review.csv",
          row.names=F)

#then we want to use the frames created above to take out those with a different time_and_date within assessment_id for review

bp_labs_internal_time_difference_rows_from_patients_with_different_date_and_time_throughout_assessment_to_review <-
  subset(bp_labs_rows_from_patients_with_large_internal_date_difference,
         record_id %in% patients_with_rows_with_different_date_and_time_within_same_assessment_id)

#order before printing
bp_labs_internal_time_difference_rows_from_patients_with_different_date_and_time_throughout_assessment_to_review <- 
  bp_labs_internal_time_difference_rows_from_patients_with_different_date_and_time_throughout_assessment_to_review[order(bp_labs_internal_time_difference_rows_from_patients_with_different_date_and_time_throughout_assessment_to_review$record_id,
                           bp_labs_internal_time_difference_rows_from_patients_with_different_date_and_time_throughout_assessment_to_review$assessment_id),] 

write.csv(bp_labs_internal_time_difference_rows_from_patients_with_different_date_and_time_throughout_assessment_to_review,
          "bp_labs_internal_time_difference_rows_from_patients_with_different_date_and_time_throughout_assessment_to_review.csv",
          row.names=F)

```


```{r, outline of method to review dates for future reference}
print("#############################Method for reviewing bp_labs_internal_date_difference_review_frame.csv#############################. Look at readings with a large labs_visit_date_labs_reading_date_difference_in_days. Check chronology of entries to see whether labs_visit_date is likely correct or date_and_time is likely correct. check whether the one you think is correct has a 1 in the labs_assessment_date_present_in_longitudinal data or the. labs_date_from_date_and_time_of_measurement_present_in_longitudinaldata columns to confirm your suspicion. If necessary, tweak the code within this file by searching above for - here is where to enter the number of days difference between readings. A stricter approach can also be to look at any entry which is '1' in with regards to labs_assessment_date_present_in_longitudinal_data AND labs_date_from_date_and_time_present_in_longitudinal_data, but the difference between dates more than 0 - this could indicate blood test date is allied to the wrong visit date. In ambiguous cases where neither date is present in the longitudinal data, you can review the bp_data file created after joining (after file 8), to see which date is closest to a visit in the longitudinal data. Use this to carry out manual corrections and to check entries with centres.")
```

#############################
Method for reviewing bp_labs_internal_date_difference_review_frame.csv
#############################

Look at readings with a large labs_visit_date_labs_reading_date_difference_in_days
Check chronology of entries to see whether labs_visit_date is likely correct or date_and_time is likely correct
check whether the one you think is correct has a 1 in the labs_assessment_date_present_in_longitudinal data or the labs_date_from_date_and_time_of_measurement_present_in_longitudinaldata columns to confirm your suspicion.
If necessary, tweak the code within this file by searching above for - here is where to enter the number of days difference between readings
In ambiguous cases where neither date is present in the longitudinal data, you can review the bp_data file created after joining (after file 8), to see which date is closest to a visit in the longitudinal data

****************
shaping corrected labs data
****************

```{r, refine id and times and visit dates}
bp_labs$row_number <- 
  as.integer(rownames(bp_labs))

bp_labs$labs_centre_name <- 
  bp_labs$centreName

bp_labs$centreName <- NULL

bp_labs$id <- 
  as.integer(bp_labs$record_id)

bp_labs$visit_date <- 
  as.POSIXct(bp_labs$assessment_date, format="%d/%m/%Y")

bp_labs$labs_date <- 
  as.POSIXct(gsub("T.*"  , "",   bp_labs$date_and_time), format="%Y-%m-%d")

bp_labs$labs_time <- 
  gsub(".*T"  , "",   bp_labs$date_and_time)

bp_labs$labs_hour <- 
  gsub(":.*"  , "",   bp_labs$labs_time)

bp_labs$labs_minutes <- 
  sub(":.."  , "", sub("..:"  , "",   bp_labs$labs_time))

bp_labs$labs_seconds <- 
  gsub(".*:"  , "",   bp_labs$labs_time)

bp_labs$labs_date_time <- 
  as.POSIXct(paste(bp_labs$labs_date, bp_labs$labs_time) , format="%Y-%m-%d %H:%M:%S")

bp_labs$id_visit_date <- paste(bp_labs$id , bp_labs$visit_date, sep="_")

```

```{r, paste columns together to be able to group similar dates times and markers }
bp_labs$marker <- 
  bp_labs$labs_type

bp_labs$id_visit_date_marker <- 
  paste(bp_labs$id , 
        bp_labs$visit_date, 
        bp_labs$marker)

bp_labs$id_visit_date_marker_labs_date <- 
  paste(bp_labs$id , 
        bp_labs$visit_date, 
        bp_labs$marker,
        bp_labs$labs_date
        )

bp_labs$id_visit_date_marker_labs_date_time <- 
  paste(bp_labs$id , 
        bp_labs$visit_date, 
        bp_labs$marker,
        bp_labs$labs_date_time)

bp_labs_id_visit_date_marker_labs_date_time_frequencies <-
  as.data.frame(freq(bp_labs$id_visit_date_marker_labs_date_time))
```

```{r, remove rows with duplications}
#eventually we want to get rid of the assessment_id, but it does have some use because it is unique within this frame, and therefore if there are, for instance, two entries with the same patient time and date, but different values, we can assume the largest assessment_id is the most recently entered one and therefore the one to go with

#then remove the duplicated entries. Unique is not good enough for this, because in some entries we have exactly the same entry, just something like 'high' put in the result column, and then the duplicate might have NA - because this column doesn't matter.
#Instead, we use add_count based on multiple columns and then filter rows that have a count of 1

#note here, we DONT want the value, as if something is entered at the same date and time, we are taking the most recent data entry to be likely the accurate one
bp_labs_duplications_completely_removed <- 
  bp_labs %>% 
  add_count(record_id, 
            assessment_date, 
            labs_type, 
            date_and_time, 
            labs_centre_name) %>% 
  filter(n == 1)

#extract the id_visit_date s with duplicated rows in the original frame
#this is people who have duplications for the listed columns

bp_labs_with_duplicated_rows <- 
  bp_labs %>% 
  add_count(record_id, 
            assessment_date, 
            labs_type, 
            date_and_time, 
            labs_centre_name) %>% 
  filter(n > 1)

write.csv(bp_labs_with_duplicated_rows, "bp_labs_with_duplicated_rows.csv")

#now we simply want to slice_max the assessment_id for any entry which has the same id_visit_date_marker_labs_date_time
bp_labs_with_duplications_isolated_to_join_back <-
  bp_labs_with_duplicated_rows %>% 
  group_by(id_visit_date_marker_labs_date_time) %>%
  slice_max(n=1, 
            with_ties=F, 
            order_by=assessment_id)

#and now we can see which visits we're removing
bp_labs_duplications_removed <-
  subset(bp_labs_with_duplicated_rows, 
         !(row_number %in% bp_labs_with_duplications_isolated_to_join_back$row_number))

print("this number should be zero to show we've not lost any rows ")
nrow(bp_labs_with_duplications_isolated_to_join_back) + 
  nrow(bp_labs_duplications_removed) - 
  nrow(bp_labs_with_duplicated_rows)

```

```{r, create a frame that now has no duplicate entries}
#now we can create bp_labs_without_duplicated_rows by binding the bp_labs_unique_duplicated_rows to bp_labs_duplications_completely_removed
bp_labs_without_duplicated_rows <-
  rbind(
    bp_labs_duplications_completely_removed,
    bp_labs_with_duplications_isolated_to_join_back
  )
```

```{r, check the frame that now has no duplicate entries}
print("the following number should be zero to prove we haven't lost anything we haven't accounted for:")
nrow(bp_labs_duplications_completely_removed) + nrow(bp_labs_with_duplicated_rows) - nrow(bp_labs)

print("this is the number of duplicated rows in the labs frame that have been removed")
nrow(bp_labs_with_duplicated_rows) - nrow(bp_labs_with_duplications_isolated_to_join_back)

print("this number should be the same as the one above to show that we have just removed duplications of rows, not all data in duplicated rows")
nrow(bp_labs) - nrow(bp_labs_without_duplicated_rows)
```

```{r, review the changed columns and print a sheet that records what we have changed}
bp_labs$assessment_date_has_been_changed <-
  ifelse(bp_labs$assessment_date != bp_labs$original_assessment_date,
         1,
         0)
print("number of assessment dates changed:")
sum(bp_labs$assessment_date_has_been_changed)

#for date_and_time we need a two step process. First check if the date_and_time was changed
bp_labs$date_and_time_has_been_changed <-
  ifelse(bp_labs$date_and_time != bp_labs$original_date_and_time & 
           !is.na(bp_labs$date_and_time) & 
           !is.na(bp_labs$original_date_and_time),
         1,
         0)
print("Number of date_and_time that had a value and were changed:")
sum(bp_labs$date_and_time_has_been_changed)

#then check if the date_and_time was substituted for the assessment_date if it was NA
bp_labs$date_and_time_has_been_changed <-
  ifelse(is.na(bp_labs$original_date_and_time),
         1,
         bp_labs$date_and_time_has_been_changed)
print("Number that didn't have a date_and_time")
sum(is.na(bp_labs$date_and_time))

print("Total number of altered date_and_time:")
sum(bp_labs$date_and_time_has_been_changed)

write.csv(bp_labs, "bp_labs_with_flags_after_all_manual_corrections.csv")
```

```{r, assess number of duplicate markers}
bp_labs_without_duplicated_rows_id_visit_date_marker_labs_date_time_frequencies <-
  as.data.frame(freq(bp_labs_without_duplicated_rows$id_visit_date_marker_labs_date_time))

duplicate_markers <- 
  rownames(
    bp_labs_without_duplicated_rows_id_visit_date_marker_labs_date_time_frequencies %>% 
             filter(Freq>1 & Freq <10000))

duplicate_marker_frame <-
  subset(bp_labs_without_duplicated_rows, 
         id_visit_date_marker_labs_date_time %in% duplicate_markers)

print("This frame should have nothing in it, so the number here should be zero:")
nrow(duplicate_marker_frame)

bp_labs_without_duplicated_rows_id_visit_date_marker_labs_date_time_frequencies <- NULL

duplicate_marker_frame <- NULL

print("the number of different id_visit_date_marker_labs_date_time that are different is")

length(duplicate_markers)

```

Now we want to spread the frame, or pivot it wider, so that all labs taken on the same date are on the same line

Remember that the assessment record date might not be the same as the labs date. We always have a visit_date in this frame, but we don't always have a labs_date

what I want to spread is labs_type to make that into a column for each reading, and within that column we want the value of that marker

for this to work, we first need to just pull out the important columns

```{r, manual review of dates in labs frame}
manual_review_visit_data <- 
  as.data.frame(freq(bp_labs_without_duplicated_rows$visit_date))

manual_review_labs_date <- 
  as.data.frame(freq(bp_labs_without_duplicated_rows$labs_date))
```

######################################################################
Using assessment_date if date_and_time is not present
######################################################################

```{r}
print("We want to know how many rows in the bp_labs frame have an assessment_date, but have NA for their date_and_time:")

print("Number with NA in assessment_date:")
sum(is.na(bp_labs$assessment_date))

print("Number with NA in date_and_time:")
sum(is.na(bp_labs$date_and_time))

#we can make the assumption of using the visit date first and foremost, if the date_and_time isn't present. 

#to do this, we first need to get the assessment_date in a format to share that is the same as that entered into the frame

bp_labs$assessment_date_to_share <-
  as.character(as.POSIXct(bp_labs$assessment_date, format="%d/%m/%Y"))

#add the time
bp_labs$assessment_date_to_share <-
  paste0(bp_labs$assessment_date_to_share,
         "TOO:OO:OO")

print("Here we use the assessment_date as a date_and_time if the date_and_time is NA, applied to the following number of rows:")
sum(is.na(bp_labs$date_and_time))

bp_labs$date_and_time <-
  ifelse(is.na(bp_labs$date_and_time),
         bp_labs$assessment_date_to_share,
         bp_labs$date_and_time)

print("The following number should now be zero showing that we have a date_and_time in every row:")

sum(is.na(bp_labs$date_and_time))
```

```{r, prepare a frame without duplications to make wide}

#I have commented/greyed out some columns now that don't need to be in the wide frame

bp_labs_to_widen <- 
  bp_labs_without_duplicated_rows[,c(
    #"id",
    "assessment_id", 
    "id_visit_date", 
    "marker",
    "result",
    "value",
    "labs_centre_name",
    "visit_date",
    "labs_date_time")]

print("Number without marker:")
sum(is.na(bp_labs_to_widen$marker))

bp_labs_to_widen$id_visit_date <- 
  as.factor(bp_labs_to_widen$id_visit_date)


```

we want the result within the labs frame to be a number - some of these have units in them
so we want to create valuenum and valuechar

here we want to tidy up the value column for censoring. If it has a limit in it, we need to take that out. If we have units in it, we have to take them out. Then we have to get the number on it's own. Then I need some sort of check for that.

```{r, remove censoring variables and make results into numbers}
print("Number without marker:")
sum(is.na(bp_labs_to_widen$marker))

bp_labs_to_widen$value_limit <- 
  ifelse(grepl(">", 
               bp_labs_to_widen$value) , 
         ">", 
         NA)

bp_labs_to_widen$value_limit <- 
  ifelse(grepl("<", 
               bp_labs_to_widen$value) , 
         "<", 
         bp_labs_to_widen$value_limit)

bp_labs_to_widen$value_units <- 
  gsub(pattern="<", 
       x=bp_labs_to_widen$value , 
       replacement="")

bp_labs_to_widen$value_units <- 
  gsub(pattern=">", 
       x=bp_labs_to_widen$value_units, 
       replacement="")

#I want to get rid of any numbers that have either a decimal point between them, or a comma which is a common typographical error and replace the comma with a point
bp_labs_to_widen$value_units <- 
  gsub(pattern="\\d", 
       x=bp_labs_to_widen$value_units , 
       replacement="")

bp_labs_to_widen$value_units <- 
  gsub(pattern="\\,", 
       x=bp_labs_to_widen$value_units, 
       replacement="")

bp_labs_to_widen$value_units <- 
  gsub(pattern="\\.", 
       x=bp_labs_to_widen$value_units, 
       replacement="")

bp_labs_to_widen$value_units <- 
  gsub(pattern="", 
       x=bp_labs_to_widen$value_units , 
       replacement="")

bp_labs_to_widen$value_units <- 
  gsub(pattern="(?:\\s?)+(?:\\s?)+", 
       x=bp_labs_to_widen$value_units, 
       replacement="")

bp_labs_to_widen$value_units <- 
  gsub(pattern="", 
       x=bp_labs_to_widen$value_units, 
       replacement="")

#remove all trailing or starting spaces
bp_labs_to_widen$value_units <- 
  gsub(pattern=" ", 
       x=bp_labs_to_widen$value_units, 
       replacement="")

#remember to convert in order - i.e. mol/l, then convert nmol/l after. All the nmol/l will convert leaving the mol/l on their own unconverted

print("Number without marker:")
sum(is.na(bp_labs_to_widen$marker))

#grams per decilitre

bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mcg/dl", "g/dl", NA)

#international units per volume
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="uUI/ml", "IU/ml", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="UI/ml", "IU/ml", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mcIU/mL", "IU/ml", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="IU/L", "IU/l", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="iu/L", "IU/l", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="iU/L", "IU/l", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mcIU//ml", "IU/ml", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mcIU/ml", "IU/ml", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mcIU/L", "IU/l", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mcui/ml", "IU/ml", bp_labs_to_widen$units)

#milliequivalents
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mEq/L", "mEq/l", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="meq/L", "mEq/l", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="meq/L", "mEq/l", bp_labs_to_widen$units)

#moles
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mcmol/l", "mol/l", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mcmol/ml", "mol/ml", bp_labs_to_widen$units)

#percentages
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mg%", "mg/dl", bp_labs_to_widen$units)

print("Number without marker:")
sum(is.na(bp_labs_to_widen$marker))

#time

bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mcg/h", "mcg/h", bp_labs_to_widen$units)

bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mkg/h", "mg/kg/hr", bp_labs_to_widen$units)

bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="ng/mL/h", "ng/ml/hr", bp_labs_to_widen$units)

bp_labs_to_widen$units <- 
  ifelse(grepl("ng/ml/hr" , bp_labs_to_widen$value_units), "ng/ml/hr", bp_labs_to_widen$units)

bp_labs_to_widen$units <- 
  ifelse(grepl("nmol/l/hr" , bp_labs_to_widen$value_units), "nmol/l/hr", bp_labs_to_widen$units)

bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="nmol/l/h", "nmol/l/hr", bp_labs_to_widen$units)

bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="nmol/l/hour", "nmol/l/hr", bp_labs_to_widen$units)

bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="nmol/L/hour", "nmol/l/hr", bp_labs_to_widen$units)

bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mol/l/h", "nmol/l/hr", bp_labs_to_widen$units)

#correct ohp17 incorrect units after liaison with centres:
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mol/l" &
           bp_labs_to_widen$marker=="ohp17", 
         "nmol/l", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mmol/l" &
           bp_labs_to_widen$marker=="ohp17", 
         "nmol/l", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mg/ml" &
           bp_labs_to_widen$marker=="ohp17", 
         "ng/ml", bp_labs_to_widen$units)

#correct androstenedione incorrect units after liaison with centres:
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mol/l" &
           bp_labs_to_widen$marker=="andostenedione", 
         "nmol/l", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mmol/l" &
           bp_labs_to_widen$marker=="andostenedione", 
         "nmol/l", bp_labs_to_widen$units)
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mg/ml" &
           bp_labs_to_widen$marker=="andostenedione", 
         "ng/ml", bp_labs_to_widen$units)

#correct renin clear incorrect units after liaison with centres:

bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mIU/ml" &
           bp_labs_to_widen$marker=="renin", 
         "IU/ml", bp_labs_to_widen$units)

bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mcIU/L" &
           bp_labs_to_widen$marker=="renin", 
         "IU/ml", bp_labs_to_widen$units)

bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$value_units=="mg/ml" &
           bp_labs_to_widen$marker=="renin", 
         "ng/ml", bp_labs_to_widen$units)

#global correction of IU/l to IU/ml for renin just to make standardisation easier
bp_labs_to_widen$units <- 
  ifelse(bp_labs_to_widen$units=="IU/l" &
           bp_labs_to_widen$marker=="renin", 
         "IU/ml", bp_labs_to_widen$units)

units_original <- 
  as.data.frame(freq(bp_labs_to_widen$value_units))

units_corrected <- 
  as.data.frame(freq(bp_labs_to_widen$units))

#once we have the units all standardised, we can correct globally for renin documented with values of plasma renin activity. If the units are nmol/l/hr, then this reading is actually a plasma renin activity, as you don't measure renin in units per hour, you only measure plasma renin activity
sum(is.na(bp_labs_to_widen$marker))

bp_labs_to_widen$marker <-
  ifelse(bp_labs_to_widen$units=="nmol/l/hr" & 
           !is.na(bp_labs_to_widen$units),
         "plasma_renin_activity",
         bp_labs_to_widen$marker)

print("Number without marker:")
sum(is.na(bp_labs_to_widen$marker))

```

now take out the number itself from the value column, and turn it into a numeric variable

```{r, ensure values are numbers and remove comma typos}
bp_labs_to_widen$value_number <- 
  gsub(pattern="<", 
       x=bp_labs_to_widen$value , 
       replacement="")

bp_labs_to_widen$value_number <- 
  gsub(pattern=">", 
       x=bp_labs_to_widen$value_number , 
       replacement="")

#this keeps all numbers that have a comma, then keeps all numbers that have a point. Then we can compare those numbers - if the columns are equal, they are whole numbers. If one of the columns as a point, then that's the number. If one of the columns has a comma, that was a typo and it needs converting to a point

bp_labs_to_widen$value_number_comma <- 
  gsub(pattern="[^0-9,-]", 
       x=bp_labs_to_widen$value_number , 
       replacement="")

bp_labs_to_widen$value_number_point <- 
  gsub(pattern="[^0-9.-]", 
       x=bp_labs_to_widen$value_number , 
       replacement="")

bp_labs_to_widen$number_corrected_for_commas <- 
  ifelse(bp_labs_to_widen$value_number_comma==bp_labs_to_widen$value_number_point ,
         bp_labs_to_widen$value_number_point, 
         NA )

bp_labs_to_widen$number_corrected_for_commas <- 
  ifelse(grepl(",", bp_labs_to_widen$value_number_comma), 
         gsub(x=bp_labs_to_widen$value_number_comma, 
              pattern=",", 
              replacement="."), 
         bp_labs_to_widen$number_corrected_for_commas)

bp_labs_to_widen$number_corrected_for_commas <- 
  ifelse(grepl("\\.", bp_labs_to_widen$value_number_point), 
         bp_labs_to_widen$value_number_point, 
         bp_labs_to_widen$number_corrected_for_commas)

check_frame <- 
  bp_labs_to_widen[,c("value", "number_corrected_for_commas")]

check_frame$difference_between_value_and_corrected_value <- 
  as.numeric(check_frame$value) - 
  as.numeric(check_frame$number_corrected_for_commas)

print("this number should be zero to show that our tidying of comma typo's hasn't changed any numbers incorrectly:")
sum(abs(check_frame$difference_between_value_and_corrected_value), na.rm=T)

#finally create value_number to be our value corrected for censoring and make it numeric
bp_labs_to_widen$value_number <- 
  as.numeric(bp_labs_to_widen$number_corrected_for_comma)

#we now have 'units' 'value' and value_limit' which is all of use, along with 'labs_hour', 'labs_minutes', 'labs_seconds' ' visit_date' 'labs_date', we should also keep the original text 'value' column along with the details of the centre etc

print("Number without marker:")
sum(is.na(bp_labs_to_widen$marker))
```

```{r, learn about units from this extraction}
units_of_markers_that_centres_use <- 
  bp_labs_to_widen[,c(
    "labs_centre_name", 
    "marker", 
    "units")]

units_of_markers_that_centres_use <- 
  unique(subset(units_of_markers_that_centres_use, 
                !is.na(units)))

write.csv(units_of_markers_that_centres_use, 
          "units_of_markers_that_centres_use_from_2021_extraction.csv")
```

we now have the frame bp_labs_to_widen to take into the next file

```{r, tidy environemnt and remove frames we have done nothing with to prevent duplicated saving}
rm(bp_participants)

rm(bp_participants_longitudinal_data)

rm(bp_labs)

rm(bp_labs_with_duplicated_rows)

rm(bp_labs_unique_duplicated_rows)

rm(bp_labs_duplications_completely_removed)

rm(bp_labs_duplications_removed)

rm(bp_labs_with_duplications_isolated_to_join_back)

rm(check_frame)

rm(bp_labs_with_baronio)
```

```{r, check the structure of the value_number}
str(bp_labs_to_widen$value_number)
```

```{r, %% number of rows removed from the labs file}
print("Number of rows in original frame")
nrow(bp_labs_original)

print("Number of rows in final frame before making it wide")
nrow(bp_labs_to_widen)

print("Number of rows removed automatically due to exact duplications:")
number_of_exact_row_duplicates_removed + number_duplicated_with_different_assessment_id

print("This means the following number of rows were removed due to manual adjustment:")
nrow(bp_labs_original)-
  nrow(bp_labs_to_widen) - 
  (number_of_exact_row_duplicates_removed + number_duplicated_with_different_assessment_id)

print("Number of rows removed in total:")
```

```{r, %% report number of values with censoring limit removed}
print("This shows the number of variables with censoring removed:")
freq(bp_labs_to_widen$value_limit )

print("Number without marker:")
sum(is.na(bp_labs_to_widen$marker))
```

```{r, %% number of assessment_dates changed}
bp_labs_without_duplicated_rows$assessment_date_changed <-
  ifelse(bp_labs_without_duplicated_rows$assessment_date !=
  bp_labs_without_duplicated_rows$original_assessment_date |
         is.na(bp_labs_without_duplicated_rows$assessment_date) &
           !is.na(bp_labs_without_duplicated_rows$original_assessment_date) |
         !is.na(bp_labs_without_duplicated_rows$assessment_date) &
           is.na(bp_labs_without_duplicated_rows$original_assessment_date),
         1,
         0)

print("Number of visits with manually corrected assessment_date")
sum(bp_labs_without_duplicated_rows$assessment_date_changed, na.rm=T)

print("Number of visits with missing assessment_date")
sum(is.na(bp_labs_without_duplicated_rows$original_assessment_date), na.rm=T)

print("Number of visits with assessment_date")
sum(!is.na(bp_labs_without_duplicated_rows$assessment_date_changed), na.rm=T)

print("Total number of rows in labs data without duplications")
nrow(bp_labs_without_duplicated_rows)

print("Number without marker:")
sum(is.na(bp_labs_to_widen$marker))
```

```{r, %% number of date_and_time changed}
bp_labs_without_duplicated_rows$date_and_time_changed <-
  ifelse(bp_labs_without_duplicated_rows$date_and_time !=
  bp_labs_without_duplicated_rows$original_date_and_time |
         is.na(bp_labs_without_duplicated_rows$date_and_time) &
           !is.na(bp_labs_without_duplicated_rows$original_date_and_time) |
         !is.na(bp_labs_without_duplicated_rows$date_and_time) &
           is.na(bp_labs_without_duplicated_rows$original_date_and_time),
         1,
         0)

print("Number of visits with manually corrected date_and_time")
sum(bp_labs_without_duplicated_rows$date_and_time_changed, na.rm=T)

print("Number of visits with missing date_and_time")
sum(is.na(bp_labs_without_duplicated_rows$original_date_and_time), na.rm=T)

print("Number of visits with date_and_time")
sum(!is.na(bp_labs_without_duplicated_rows$date_and_time_changed), na.rm=T)

print("Total number of rows in labs data without duplications")
nrow(bp_labs_without_duplicated_rows)

print("Number without marker:")
sum(is.na(bp_labs_to_widen$marker))
```

```{r, turn id_visit_date into a character before saving}
bp_labs_to_widen$id_visit_date <- 
  as.character(bp_labs_to_widen$id_visit_date)
```

```{r, separate out markers to be able to assess and manually correct for renin that should be plasma renin activity and vice versa}
print("Number without marker:")
sum(is.na(bp_labs_to_widen$marker))

unique(bp_labs_to_widen$marker)

bp_labs_to_widen_renin <-
  subset(bp_labs_to_widen, marker=="renin")
print("These are the units we have extracted from the registry for renin:")
unique(bp_labs_to_widen_renin$units)

bp_labs_to_widen_plasma_renin_activity <-
  subset(bp_labs_to_widen, marker=="plasma_renin_activity")
print("These are the units we have extracted from the registry for plasma renin activity:")
unique(bp_labs_to_widen_plasma_renin_activity$units)

bp_labs_to_widen_17OHP <-
  subset(bp_labs_to_widen, marker=="ohp17")
print("These are the units we have extracted from the registry for 17OHP:")
unique(bp_labs_to_widen_17OHP$units)

bp_labs_to_widen_androstenedione <-
  subset(bp_labs_to_widen, marker=="andostenedione")
print("These are the units we have extracted from the registry for Androstenedione:")
unique(bp_labs_to_widen_androstenedione$units)

bp_labs_to_widen_sodium <-
  subset(bp_labs_to_widen, marker=="sodium")
print("These are the units we have extracted from the registry for Sodium:")
unique(bp_labs_to_widen_sodium$units)

bp_labs_to_widen_potassium <-
  subset(bp_labs_to_widen, marker=="potassium")
print("These are the units we have extracted from the registry for Potassium:")
unique(bp_labs_to_widen_potassium$units)

unique(bp_labs_to_widen$marker)
```

```{r, end of file so save all the listed dataframes into the parent directory}
save_bp_files_function(
  parent_directory=location_of_data_files,
  parent_file="file_4")
Sys.time()
```
